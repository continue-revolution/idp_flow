{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.base import Base\n",
    "base = Base(16, 128)\n",
    "samples, base_log_det = base.sample_and_log_prob(128)\n",
    "samples.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models.base.Base & models.bijectors.CircularShift Test\n",
    "\n",
    "Problem: nflow generate samples whose require_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from models.bijectors import CircularShift\n",
    "from torch.nn import Parameter\n",
    "samples.requires_grad=True\n",
    "shift = Parameter(\n",
    "    torch.rand(size=(1, )))\n",
    "circular_shift = CircularShift(shift, -torch.pi, torch.pi)\n",
    "shift_result, shift_logdet = circular_shift(samples)\n",
    "shift_mean = shift_result.sum()\n",
    "shift_mean.backward()\n",
    "print(samples.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import make_model\n",
    "from experiments.configs import get_config\n",
    "config = get_config(16)\n",
    "model, energy_fn = make_model(\n",
    "    -torch.pi, torch.pi, **config.model['kwargs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transforms import Dihedral2Coord\n",
    "from models.energy import Energy\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "trans = Dihedral2Coord(\n",
    "    mol=model._distribution.mol,\n",
    "    angles=model._distribution.torsion_angles)\n",
    "energy = Energy(\n",
    "    mol=model._distribution.mol)\n",
    "angles_sample = torch.rand(size=(128, 8), requires_grad=True)\n",
    "coord_sample = trans(angles_sample)\n",
    "loss = coord_sample.sum()\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(angles_sample.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logdet = model.sample_and_log_prob(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss = (loss + logdet[:, None]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0239, -0.3383,  0.3175,  ..., -0.1333, -0.3284, -0.4040],\n",
       "        [-0.1827,  1.1365, -0.5813,  ..., -0.3947,  0.3445,  0.7744],\n",
       "        [-0.0460,  0.5030, -0.5148,  ..., -0.1440,  0.2224,  0.9553],\n",
       "        ...,\n",
       "        [ 0.9095, -0.1586,  0.2059,  ...,  0.0287, -0.6542, -0.1489],\n",
       "        [-0.2702, -0.0838,  0.3339,  ..., -0.3490,  0.1917, -0.4530],\n",
       "        [-0.1773,  0.2773, -0.5189,  ..., -0.1973, -0.0033,  0.5414]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._transform._transforms[0]._transforms[1].conditioner.linear1.weight.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660],\n",
       "        [-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660],\n",
       "        [-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660],\n",
       "        ...,\n",
       "        [-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660],\n",
       "        [-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660],\n",
       "        [-0.3250, -0.3333,  0.1653,  ..., -0.1855,  0.2534,  0.0660]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_linear = torch.nn.Linear(8, 1)\n",
    "loss2 = tmp_linear(angles_sample).sum()\n",
    "loss2.backward()\n",
    "angles_sample.grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 17])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.rand(size=(4, 17))\n",
    "k = torch.rand(size=(4, 17))\n",
    "l = torch.rand(size=(4, 17))\n",
    "ls = [j, k, l]\n",
    "torch.stack(ls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8167, 0.5797, 3.3655, 0.3703],\n",
       "         [0.7785, 2.3855, 0.4710, 2.0032],\n",
       "         [0.9357, 2.4022, 0.5809, 1.4372],\n",
       "         [0.9357, 2.4022, 0.4772, 0.6444],\n",
       "         [0.8134, 0.5167, 0.5041, 1.9168]]),\n",
       " tensor([[-2.0675, -1.5534,     nan, -0.5470],\n",
       "         [-2.0675,     nan, -1.2066,     nan],\n",
       "         [    nan,     nan, -0.1418,     nan],\n",
       "         [    nan,     nan, -1.2066, -1.1884],\n",
       "         [-2.0675, -1.5534, -0.1418,     nan]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "i=torch.rand(size=(5,4))\n",
    "j=torch.rand(size=(4, 17))\n",
    "k=torch.rand(size=(4, 17))\n",
    "l=torch.rand(size=(4, 17))\n",
    "from models.spline import _rational_quadratic_spline_fwd\n",
    "_rational_quadratic_spline_fwd(i,j,k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "def _rqs_fwd_single(x: Tensor,\n",
    "                                   x_pos: Tensor,\n",
    "                                   y_pos: Tensor,\n",
    "                                   knot_slopes: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "  \"\"\"Applies a rational-quadratic spline to a scalar.\n",
    "  Args:\n",
    "    x: a scalar (0-dimensional array). The scalar `x` can be any real number; it\n",
    "      will be transformed by the spline if it's in the closed interval\n",
    "      `[x_pos[0], x_pos[-1]]`, and it will be transformed linearly if it's\n",
    "      outside that interval.\n",
    "    x_pos: array of shape [num_bins + 1], the bin boundaries on the x axis.\n",
    "    y_pos: array of shape [num_bins + 1], the bin boundaries on the y axis.\n",
    "    knot_slopes: array of shape [num_bins + 1], the slopes at the knot points.\n",
    "  Returns:\n",
    "    A tuple of two scalars: the output of the transformation and the log of the\n",
    "    absolute first derivative at `x`.\n",
    "  \"\"\"\n",
    "  # Search to find the right bin. NOTE: The bins are sorted, so we could use\n",
    "  # binary search, but this is more GPU/TPU friendly.\n",
    "  # The following implementation avoids indexing for faster TPU computation.\n",
    "  below_range = x <= x_pos[0]\n",
    "  above_range = x >= x_pos[-1]\n",
    "  correct_bin = torch.logical_and(x >= x_pos[:-1], x < x_pos[1:])\n",
    "  any_bin_in_range = torch.any(correct_bin)\n",
    "  first_bin = torch.concat([torch.tensor([1], dtype=bool),\n",
    "                               torch.zeros(len(correct_bin)-1, dtype=bool)])\n",
    "  # If y does not fall into any bin, we use the first spline in the following\n",
    "  # computations to avoid numerical issues.\n",
    "  correct_bin = torch.where(any_bin_in_range, correct_bin, first_bin)\n",
    "  # Dot product of each parameter with the correct bin mask.\n",
    "  params = torch.stack([x_pos, y_pos, knot_slopes], axis=1)\n",
    "  params_bin_left = torch.sum(correct_bin[:, None] * params[:-1], axis=0)\n",
    "  params_bin_right = torch.sum(correct_bin[:, None] * params[1:], axis=0)\n",
    "\n",
    "  x_pos_bin = (params_bin_left[0], params_bin_right[0])\n",
    "  y_pos_bin = (params_bin_left[1], params_bin_right[1])\n",
    "  knot_slopes_bin = (params_bin_left[2], params_bin_right[2])\n",
    "\n",
    "  bin_width = x_pos_bin[1] - x_pos_bin[0]\n",
    "  bin_height = y_pos_bin[1] - y_pos_bin[0]\n",
    "  bin_slope = bin_height / bin_width\n",
    "\n",
    "  z = (x - x_pos_bin[0]) / bin_width\n",
    "  # `z` should be in range [0, 1] to avoid NaNs later. This can happen because\n",
    "  # of small floating point issues or when x is outside of the range of bins.\n",
    "  # To avoid all problems, we restrict z in [0, 1].\n",
    "  z = torch.clip(z, 0., 1.)\n",
    "  sq_z = z * z\n",
    "  z1mz = z - sq_z  # z(1-z)\n",
    "  sq_1mz = (1. - z) ** 2\n",
    "  slopes_term = knot_slopes_bin[1] + knot_slopes_bin[0] - 2. * bin_slope\n",
    "  numerator = bin_height * (bin_slope * sq_z + knot_slopes_bin[0] * z1mz)\n",
    "  denominator = bin_slope + slopes_term * z1mz\n",
    "  y = y_pos_bin[0] + numerator / denominator\n",
    "\n",
    "  # Compute log det Jacobian.\n",
    "  # The logdet is a sum of 3 logs. It is easy to see that the inputs of the\n",
    "  # first two logs are guaranteed to be positive because we ensured that z is in\n",
    "  # [0, 1]. This is also true of the log(denominator) because:\n",
    "  # denominator\n",
    "  # == bin_slope + (knot_slopes_bin[1] + knot_slopes_bin[0] - 2 * bin_slope) *\n",
    "  # z*(1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * z * (1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * (1/4)\n",
    "  # == bin_slope / 2\n",
    "  logdet = 2. * torch.log(bin_slope) + torch.log(\n",
    "      knot_slopes_bin[1] * sq_z + 2. * bin_slope * z1mz +\n",
    "      knot_slopes_bin[0] * sq_1mz) - 2. * torch.log(denominator)\n",
    "\n",
    "  # If x is outside the spline range, we default to a linear transformation.\n",
    "  y = torch.where(below_range, (x - x_pos[0]) * knot_slopes[0] + y_pos[0], y)\n",
    "  y = torch.where(above_range, (x - x_pos[-1]) * knot_slopes[-1] + y_pos[-1], y)\n",
    "  logdet = torch.where(below_range, torch.log(knot_slopes[0]), logdet)\n",
    "  logdet = torch.where(above_range, torch.log(knot_slopes[-1]), logdet)\n",
    "  return y, logdet\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "729135a7fed3b567d634efcd54e452b1f1e9c908d616bc775570d26a0a8b03e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
