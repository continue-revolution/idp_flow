{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.base import Base\n",
    "base = Base(16, 128)\n",
    "samples, base_log_det = base.sample_and_log_prob(128)\n",
    "samples.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models.base.Base & models.bijectors.CircularShift Test\n",
    "\n",
    "Problem: nflow generate samples whose require_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from models.bijectors import CircularShift\n",
    "from torch.nn import Parameter\n",
    "samples.requires_grad=True\n",
    "shift = Parameter(\n",
    "    torch.rand(size=(1, )))\n",
    "circular_shift = CircularShift(shift, -torch.pi, torch.pi)\n",
    "shift_result, shift_logdet = circular_shift(samples)\n",
    "shift_mean = shift_result.sum()\n",
    "shift_mean.backward()\n",
    "print(samples.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import make_model\n",
    "from experiments.configs import get_config\n",
    "config = get_config(16)\n",
    "model, energy_fn = make_model(\n",
    "    -torch.pi, torch.pi, **config.model['kwargs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transforms import Dihedral2Coord\n",
    "from models.energy import Energy\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "trans = Dihedral2Coord(\n",
    "    mol=model._distribution.mol,\n",
    "    angles=model._distribution.torsion_angles)\n",
    "energy = Energy(\n",
    "    mol=model._distribution.mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11,  0,  1,  2],\n",
       "        [10,  1,  2,  3],\n",
       "        [ 6,  2,  3,  5],\n",
       "        [15,  4,  0, 11],\n",
       "        [14,  5,  3,  2],\n",
       "        [ 7,  6,  2,  3],\n",
       "        [ 8,  7,  6,  2],\n",
       "        [ 9,  8,  7,  6],\n",
       "        [12,  9,  8,  7]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._distribution.torsion_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_sample = torch.rand(size=(128, 9), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0490e-05, grad_fn=<MaxBackward1>) tensor(13194) tensor(12103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Error detected in BmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2866, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3071, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-115-f286c8b6ef11>\", line 1, in <module>\n",
      "    coord_sample = trans(angles_sample)\n",
      "  File \"c:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"f:\\hw\\Research\\CASI\\idp_nf_code\\models\\transforms.py\", line 174, in forward\n",
      "    pos = self.setDihedralRad(input[:, i], self.angles[i, :], pos)\n",
      "  File \"f:\\hw\\Research\\CASI\\idp_nf_code\\models\\transforms.py\", line 147, in setDihedralRad\n",
      "    pos[:, torch.tensor([it]), :] = data.bmm(pos[:, it, :, None]).squeeze()[:, None, :]\n",
      " (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 3, 1]], which is output 0 of AsStridedBackward0, is at version 1515; expected version 1512 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-f286c8b6ef11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# energy_sample = energy(coord_sample)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoord_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\继续革命\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 3, 1]], which is output 0 of AsStridedBackward0, is at version 1515; expected version 1512 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "coord_sample = trans(angles_sample)\n",
    "# energy_sample = energy(coord_sample)\n",
    "loss = coord_sample.sum()\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logdet = model.sample_and_log_prob(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss = (loss + logdet[:, None]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0239, -0.3383,  0.3175,  ..., -0.1333, -0.3284, -0.4040],\n",
       "        [-0.1827,  1.1365, -0.5813,  ..., -0.3947,  0.3445,  0.7744],\n",
       "        [-0.0460,  0.5030, -0.5148,  ..., -0.1440,  0.2224,  0.9553],\n",
       "        ...,\n",
       "        [ 0.9095, -0.1586,  0.2059,  ...,  0.0287, -0.6542, -0.1489],\n",
       "        [-0.2702, -0.0838,  0.3339,  ..., -0.3490,  0.1917, -0.4530],\n",
       "        [-0.1773,  0.2773, -0.5189,  ..., -0.1973, -0.0033,  0.5414]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model._transform._transforms[0]._transforms[1].conditioner.linear1.weight.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 17])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.rand(size=(4, 17))\n",
    "k = torch.rand(size=(4, 17))\n",
    "l = torch.rand(size=(4, 17))\n",
    "ls = [j, k, l]\n",
    "torch.stack(ls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8167, 0.5797, 3.3655, 0.3703],\n",
       "         [0.7785, 2.3855, 0.4710, 2.0032],\n",
       "         [0.9357, 2.4022, 0.5809, 1.4372],\n",
       "         [0.9357, 2.4022, 0.4772, 0.6444],\n",
       "         [0.8134, 0.5167, 0.5041, 1.9168]]),\n",
       " tensor([[-2.0675, -1.5534,     nan, -0.5470],\n",
       "         [-2.0675,     nan, -1.2066,     nan],\n",
       "         [    nan,     nan, -0.1418,     nan],\n",
       "         [    nan,     nan, -1.2066, -1.1884],\n",
       "         [-2.0675, -1.5534, -0.1418,     nan]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "i=torch.rand(size=(5,4))\n",
    "j=torch.rand(size=(4, 17))\n",
    "k=torch.rand(size=(4, 17))\n",
    "l=torch.rand(size=(4, 17))\n",
    "from models.spline import _rational_quadratic_spline_fwd\n",
    "_rational_quadratic_spline_fwd(i,j,k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "def _rqs_fwd_single(x: Tensor,\n",
    "                                   x_pos: Tensor,\n",
    "                                   y_pos: Tensor,\n",
    "                                   knot_slopes: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "  \"\"\"Applies a rational-quadratic spline to a scalar.\n",
    "  Args:\n",
    "    x: a scalar (0-dimensional array). The scalar `x` can be any real number; it\n",
    "      will be transformed by the spline if it's in the closed interval\n",
    "      `[x_pos[0], x_pos[-1]]`, and it will be transformed linearly if it's\n",
    "      outside that interval.\n",
    "    x_pos: array of shape [num_bins + 1], the bin boundaries on the x axis.\n",
    "    y_pos: array of shape [num_bins + 1], the bin boundaries on the y axis.\n",
    "    knot_slopes: array of shape [num_bins + 1], the slopes at the knot points.\n",
    "  Returns:\n",
    "    A tuple of two scalars: the output of the transformation and the log of the\n",
    "    absolute first derivative at `x`.\n",
    "  \"\"\"\n",
    "  # Search to find the right bin. NOTE: The bins are sorted, so we could use\n",
    "  # binary search, but this is more GPU/TPU friendly.\n",
    "  # The following implementation avoids indexing for faster TPU computation.\n",
    "  below_range = x <= x_pos[0]\n",
    "  above_range = x >= x_pos[-1]\n",
    "  correct_bin = torch.logical_and(x >= x_pos[:-1], x < x_pos[1:])\n",
    "  any_bin_in_range = torch.any(correct_bin)\n",
    "  first_bin = torch.concat([torch.tensor([1], dtype=bool),\n",
    "                               torch.zeros(len(correct_bin)-1, dtype=bool)])\n",
    "  # If y does not fall into any bin, we use the first spline in the following\n",
    "  # computations to avoid numerical issues.\n",
    "  correct_bin = torch.where(any_bin_in_range, correct_bin, first_bin)\n",
    "  # Dot product of each parameter with the correct bin mask.\n",
    "  params = torch.stack([x_pos, y_pos, knot_slopes], axis=1)\n",
    "  params_bin_left = torch.sum(correct_bin[:, None] * params[:-1], axis=0)\n",
    "  params_bin_right = torch.sum(correct_bin[:, None] * params[1:], axis=0)\n",
    "\n",
    "  x_pos_bin = (params_bin_left[0], params_bin_right[0])\n",
    "  y_pos_bin = (params_bin_left[1], params_bin_right[1])\n",
    "  knot_slopes_bin = (params_bin_left[2], params_bin_right[2])\n",
    "\n",
    "  bin_width = x_pos_bin[1] - x_pos_bin[0]\n",
    "  bin_height = y_pos_bin[1] - y_pos_bin[0]\n",
    "  bin_slope = bin_height / bin_width\n",
    "\n",
    "  z = (x - x_pos_bin[0]) / bin_width\n",
    "  # `z` should be in range [0, 1] to avoid NaNs later. This can happen because\n",
    "  # of small floating point issues or when x is outside of the range of bins.\n",
    "  # To avoid all problems, we restrict z in [0, 1].\n",
    "  z = torch.clip(z, 0., 1.)\n",
    "  sq_z = z * z\n",
    "  z1mz = z - sq_z  # z(1-z)\n",
    "  sq_1mz = (1. - z) ** 2\n",
    "  slopes_term = knot_slopes_bin[1] + knot_slopes_bin[0] - 2. * bin_slope\n",
    "  numerator = bin_height * (bin_slope * sq_z + knot_slopes_bin[0] * z1mz)\n",
    "  denominator = bin_slope + slopes_term * z1mz\n",
    "  y = y_pos_bin[0] + numerator / denominator\n",
    "\n",
    "  # Compute log det Jacobian.\n",
    "  # The logdet is a sum of 3 logs. It is easy to see that the inputs of the\n",
    "  # first two logs are guaranteed to be positive because we ensured that z is in\n",
    "  # [0, 1]. This is also true of the log(denominator) because:\n",
    "  # denominator\n",
    "  # == bin_slope + (knot_slopes_bin[1] + knot_slopes_bin[0] - 2 * bin_slope) *\n",
    "  # z*(1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * z * (1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * (1/4)\n",
    "  # == bin_slope / 2\n",
    "  logdet = 2. * torch.log(bin_slope) + torch.log(\n",
    "      knot_slopes_bin[1] * sq_z + 2. * bin_slope * z1mz +\n",
    "      knot_slopes_bin[0] * sq_1mz) - 2. * torch.log(denominator)\n",
    "\n",
    "  # If x is outside the spline range, we default to a linear transformation.\n",
    "  y = torch.where(below_range, (x - x_pos[0]) * knot_slopes[0] + y_pos[0], y)\n",
    "  y = torch.where(above_range, (x - x_pos[-1]) * knot_slopes[-1] + y_pos[-1], y)\n",
    "  logdet = torch.where(below_range, torch.log(knot_slopes[0]), logdet)\n",
    "  logdet = torch.where(above_range, torch.log(knot_slopes[-1]), logdet)\n",
    "  return y, logdet\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "729135a7fed3b567d634efcd54e452b1f1e9c908d616bc775570d26a0a8b03e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
