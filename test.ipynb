{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.base import Base\n",
    "base = Base(16, 128)\n",
    "samples, base_log_det = base.sample_and_log_prob(128)\n",
    "samples.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models.base.Base & models.bijectors.CircularShift Test\n",
    "\n",
    "Problem: nflow generate samples whose require_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "from models.bijectors import CircularShift\n",
    "from torch.nn import Parameter\n",
    "samples.requires_grad=True\n",
    "shift = Parameter(\n",
    "    torch.rand(size=(1, )))\n",
    "circular_shift = CircularShift(shift, -torch.pi, torch.pi)\n",
    "shift_result, shift_logdet = circular_shift(samples)\n",
    "shift_mean = shift_result.sum()\n",
    "shift_mean.backward()\n",
    "print(samples.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import make_model\n",
    "from experiments.configs import get_config\n",
    "config = get_config(16)\n",
    "model, energy_fn = make_model(\n",
    "    -torch.pi, torch.pi, **config.model['kwargs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transforms import Dihedral2Coord\n",
    "from models.energy import Energy\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "trans = Dihedral2Coord(\n",
    "    mol=model._distribution.mol,\n",
    "    angles=model._distribution.torsion_angles)\n",
    "energy = Energy(\n",
    "    mol=model._distribution.mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  0,  1,  2],\n",
       "        [ 0,  1,  2,  3],\n",
       "        [ 1,  2,  3,  4],\n",
       "        [10,  4,  3,  2],\n",
       "        [ 9,  8,  0,  7],\n",
       "        [12,  9,  8,  0],\n",
       "        [11, 10,  4,  3],\n",
       "        [13, 12,  9,  8],\n",
       "        [14, 13, 12,  9]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._distribution.torsion_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_sample = torch.rand(size=(128, 9), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_sample = trans(angles_sample)\n",
    "# energy_sample = energy(coord_sample)\n",
    "loss = coord_sample.sum()\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4712e+06,  1.2697e+05,  1.0514e+05, -1.8412e+04,  2.0643e+04,\n",
      "          7.9195e+03,  6.9252e+02,  2.2275e+03,  1.7376e+03],\n",
      "        [ 9.4567e+05,  3.4934e+05,  1.0922e+05, -1.8292e+04,  2.0292e+04,\n",
      "          7.9125e+03,  2.2813e+02,  2.1942e+03,  1.4476e+03],\n",
      "        [ 1.2282e+06,  3.7846e+05,  1.0248e+05, -1.8344e+04,  2.0071e+04,\n",
      "          7.5448e+03,  2.1850e+02,  1.5061e+03,  1.0294e+03],\n",
      "        [ 1.0885e+06,  3.5114e+05,  1.0283e+05, -1.8010e+04,  2.0251e+04,\n",
      "          7.8131e+03,  2.8350e+02,  2.0581e+03,  1.4447e+03],\n",
      "        [ 1.4428e+06,  3.8326e+05,  9.8304e+04, -1.8579e+04,  2.0301e+04,\n",
      "          7.8922e+03,  1.5084e+02,  1.8616e+03,  1.3737e+03],\n",
      "        [ 9.0170e+05,  3.5625e+05,  1.0238e+05, -1.9062e+04,  2.0364e+04,\n",
      "          7.8261e+03, -1.4469e+02,  2.0078e+03,  1.4405e+03],\n",
      "        [ 1.2829e+06,  3.8312e+05,  1.0156e+05, -1.8460e+04,  2.0434e+04,\n",
      "          7.8278e+03,  1.4436e+02,  1.8964e+03,  1.6475e+03],\n",
      "        [ 1.3119e+06,  4.0239e+05,  1.0113e+05, -1.8664e+04,  2.0533e+04,\n",
      "          7.9084e+03,  2.7227e+02,  1.6646e+03,  1.1020e+03],\n",
      "        [ 1.2276e+06,  4.7573e+05,  1.0074e+05, -1.8684e+04,  2.0656e+04,\n",
      "          7.8564e+03,  3.8139e+02,  1.4325e+03,  7.4273e+02],\n",
      "        [ 1.5014e+06,  3.9328e+05,  9.1212e+04, -1.8093e+04,  2.0764e+04,\n",
      "          7.5679e+03,  6.2478e+02,  9.5185e+02,  6.5607e+02],\n",
      "        [ 9.2702e+05,  3.3988e+05,  1.1654e+05, -1.8192e+04,  2.0758e+04,\n",
      "          8.1355e+03,  6.0144e+02,  2.2134e+03,  1.5360e+03],\n",
      "        [ 1.2402e+06,  3.7002e+05,  9.9518e+04, -1.8790e+04,  2.0314e+04,\n",
      "          7.7949e+03,  2.8089e+02,  1.9365e+03,  1.7979e+03],\n",
      "        [ 1.1770e+06,  3.0270e+05,  1.0239e+05, -1.8595e+04,  2.0307e+04,\n",
      "          7.8249e+03, -2.7012e+02,  1.9260e+03,  8.9763e+02],\n",
      "        [ 1.4145e+06,  3.6583e+05,  1.0103e+05, -1.7792e+04,  2.0721e+04,\n",
      "          7.4809e+03,  5.4896e+02,  1.1271e+03,  7.4187e+02],\n",
      "        [ 1.1289e+06,  3.5341e+05,  9.9985e+04, -1.8971e+04,  2.0518e+04,\n",
      "          7.6954e+03,  1.4866e+02,  1.6468e+03,  1.4829e+03],\n",
      "        [ 1.1187e+06,  3.6140e+05,  1.0221e+05, -1.8325e+04,  2.0317e+04,\n",
      "          7.6854e+03, -1.1220e+02,  1.5309e+03,  6.1146e+02],\n",
      "        [ 2.9718e+06,  2.8164e+06, -6.6759e+05, -1.7741e+04,  2.0585e+04,\n",
      "          7.6854e+03,  7.3390e+02,  1.3101e+03,  6.3560e+02],\n",
      "        [ 1.2363e+06,  4.1708e+05,  1.0168e+05, -1.8246e+04,  2.0342e+04,\n",
      "          7.5573e+03,  3.8106e+02,  1.6125e+03,  9.2824e+02],\n",
      "        [ 1.1265e+06,  3.8420e+05,  9.2622e+04, -1.8109e+04,  2.0192e+04,\n",
      "          7.9274e+03, -2.9096e+01,  1.9238e+03,  1.0421e+03],\n",
      "        [ 1.4845e+06,  3.3447e+05,  1.0096e+05, -1.8326e+04,  2.0295e+04,\n",
      "          8.1361e+03,  3.3213e+02,  2.0755e+03,  1.2689e+03],\n",
      "        [ 1.1402e+06,  3.7449e+05,  1.0244e+05, -1.8597e+04,  2.0539e+04,\n",
      "          7.6518e+03,  7.6828e+02,  1.5308e+03,  1.5426e+03],\n",
      "        [ 1.2541e+06,  3.8491e+05,  1.0104e+05, -1.8654e+04,  2.0347e+04,\n",
      "          7.8552e+03, -4.7969e+01,  1.8050e+03,  1.3392e+03],\n",
      "        [ 1.2623e+06,  3.8172e+05,  1.0419e+05, -1.8117e+04,  2.0525e+04,\n",
      "          7.8160e+03,  4.5226e+02,  1.8020e+03,  1.1947e+03],\n",
      "        [ 1.3556e+06,  3.4814e+05,  1.0385e+05, -1.8248e+04,  2.0310e+04,\n",
      "          7.4466e+03,  3.7893e+02,  1.4619e+03,  9.0669e+02],\n",
      "        [ 1.1595e+06,  3.8442e+05,  1.0113e+05, -1.8596e+04,  2.0392e+04,\n",
      "          7.9484e+03,  1.7125e+02,  1.9090e+03,  1.1480e+03],\n",
      "        [ 1.3748e+06,  3.4828e+05,  1.0008e+05, -1.8373e+04,  2.0412e+04,\n",
      "          8.0116e+03,  5.0515e+02,  1.7797e+03,  9.7005e+02],\n",
      "        [ 1.1430e+06,  4.8427e+05,  9.5183e+04, -1.8500e+04,  2.0712e+04,\n",
      "          7.7355e+03,  8.1356e+02,  1.6216e+03,  1.3971e+03],\n",
      "        [ 1.1647e+06,  3.8070e+05,  1.3193e+05, -1.8601e+04,  2.0220e+04,\n",
      "          7.4481e+03,  1.7464e+02,  1.4694e+03,  1.1301e+03],\n",
      "        [-1.0538e+06,  6.4896e+05,  1.0121e+05, -1.8864e+04,  2.0452e+04,\n",
      "          7.7224e+03,  2.1749e+02,  1.6142e+03,  1.7332e+03],\n",
      "        [ 1.0931e+06,  3.8446e+05,  1.0111e+05, -1.8778e+04,  2.0649e+04,\n",
      "          7.7348e+03,  4.1732e+02,  1.3650e+03,  9.6143e+02],\n",
      "        [ 1.6859e+06,  2.9302e+05,  1.0134e+05, -1.8502e+04,  2.0631e+04,\n",
      "          8.0289e+03,  2.6265e+02,  2.0912e+03,  1.4397e+03],\n",
      "        [-1.4047e+06,  4.5115e+05,  1.0125e+05, -1.8585e+04,  2.0353e+04,\n",
      "          7.9464e+03,  2.0052e+02,  1.9672e+03,  1.4601e+03],\n",
      "        [ 1.2282e+06,  3.9712e+05,  1.0027e+05, -1.8968e+04,  2.0333e+04,\n",
      "          7.7241e+03, -6.7852e+01,  1.6519e+03,  1.0527e+03],\n",
      "        [ 9.3793e+05,  4.4097e+05,  9.6573e+04, -1.8563e+04,  2.0547e+04,\n",
      "          7.7233e+03,  1.0213e+03,  2.0345e+03,  1.8387e+03],\n",
      "        [ 1.1096e+06,  3.4314e+05,  1.0171e+05, -1.8735e+04,  2.0107e+04,\n",
      "          7.5602e+03,  2.0636e+01,  1.6022e+03,  1.1092e+03],\n",
      "        [ 1.0745e+06,  3.7838e+05,  1.0111e+05, -1.9054e+04,  2.0286e+04,\n",
      "          7.9271e+03, -3.7870e+01,  2.1576e+03,  1.7695e+03],\n",
      "        [ 4.9173e+05,  3.5913e+05,  1.0024e+05, -1.8427e+04,  2.0184e+04,\n",
      "          7.7767e+03,  2.4979e+02,  1.5742e+03,  8.5074e+02],\n",
      "        [ 6.1810e+05,  3.8725e+05,  1.0111e+05, -1.8556e+04,  2.0323e+04,\n",
      "          8.1160e+03,  2.9802e+02,  2.1503e+03,  1.3216e+03],\n",
      "        [ 8.6109e+05,  4.4940e+05,  1.0192e+05, -1.8440e+04,  2.0483e+04,\n",
      "          7.9571e+03,  4.3167e+02,  2.4048e+03,  1.8433e+03],\n",
      "        [ 9.6155e+05,  3.8361e+05,  1.0214e+05, -1.8690e+04,  2.0236e+04,\n",
      "          7.8134e+03, -1.2628e+02,  1.7288e+03,  9.3533e+02],\n",
      "        [ 1.7995e+06,  5.8295e+05,  1.1254e+05, -1.8251e+04,  2.0803e+04,\n",
      "          7.9087e+03,  5.6345e+02,  1.8233e+03,  1.2631e+03],\n",
      "        [ 1.8503e+06,  3.8538e+05,  1.0402e+05, -1.8355e+04,  2.0297e+04,\n",
      "          7.9664e+03,  2.2281e+02,  2.1875e+03,  1.2212e+03],\n",
      "        [ 1.1753e+06,  3.7109e+05,  1.0187e+05, -1.8373e+04,  2.0261e+04,\n",
      "          7.9793e+03,  3.6133e+02,  2.0114e+03,  1.3434e+03],\n",
      "        [ 7.6726e+05,  3.5821e+05,  1.0235e+05, -1.8441e+04,  2.0108e+04,\n",
      "          7.3589e+03,  3.2309e+02,  1.3196e+03,  8.3387e+02],\n",
      "        [ 1.2504e+06,  3.2309e+05,  1.0084e+05, -1.8556e+04,  2.0155e+04,\n",
      "          8.0186e+03,  2.3926e+02,  2.3051e+03,  1.4847e+03],\n",
      "        [ 1.3419e+06,  3.8321e+05,  1.0111e+05, -1.8519e+04,  2.0374e+04,\n",
      "          7.6458e+03,  2.1613e+01,  1.6618e+03,  1.5686e+03],\n",
      "        [ 1.2726e+06,  4.0991e+05,  1.0124e+05, -1.8813e+04,  2.0286e+04,\n",
      "          7.8819e+03,  1.7564e+01,  1.8162e+03,  1.0383e+03],\n",
      "        [ 1.0188e+06,  3.6420e+05,  1.0769e+05, -1.7726e+04,  2.0494e+04,\n",
      "          7.7192e+03,  6.9987e+02,  1.4836e+03,  4.6434e+02],\n",
      "        [ 9.5952e+05,  3.8487e+05,  1.0882e+05, -1.8231e+04,  2.0259e+04,\n",
      "          7.8522e+03,  1.8288e+02,  1.9261e+03,  9.8447e+02],\n",
      "        [ 1.1486e+06,  3.2117e+05,  1.1317e+05, -1.8655e+04,  2.0533e+04,\n",
      "          7.5986e+03,  7.1604e+01,  1.4093e+03,  9.5790e+02],\n",
      "        [ 1.1412e+06,  3.6779e+05,  1.0072e+05, -1.8055e+04,  2.0310e+04,\n",
      "          7.8030e+03,  3.1429e+02,  1.8100e+03,  7.9700e+02],\n",
      "        [ 1.3264e+06,  3.8156e+05,  1.0295e+05, -1.8882e+04,  2.0232e+04,\n",
      "          8.0083e+03,  2.4376e+02,  2.6214e+03,  1.6153e+03],\n",
      "        [ 1.3538e+06,  3.7711e+05,  1.0280e+05, -1.7953e+04,  2.0624e+04,\n",
      "          7.6263e+03,  7.6848e+02,  1.2297e+03,  4.1069e+02],\n",
      "        [ 3.0844e+06,  5.1914e+05,  1.0369e+05, -1.7801e+04,  2.0589e+04,\n",
      "          7.6720e+03,  5.8097e+02,  1.1297e+03,  4.3375e+02],\n",
      "        [ 1.3136e+06,  3.8319e+05,  1.0315e+05, -1.7982e+04,  2.0681e+04,\n",
      "          7.7603e+03,  7.3415e+02,  1.6507e+03,  1.2037e+03],\n",
      "        [ 1.2542e+06,  3.8524e+05,  1.0099e+05, -1.8544e+04,  2.0092e+04,\n",
      "          7.9202e+03, -3.4024e+02,  2.4407e+03,  1.4897e+03],\n",
      "        [ 1.1677e+06,  3.5484e+05,  1.0256e+05, -1.8197e+04,  2.0453e+04,\n",
      "          7.8855e+03,  5.2668e+02,  1.8544e+03,  1.0922e+03],\n",
      "        [ 1.4103e+06,  3.1149e+05,  1.4348e+05, -1.8544e+04,  2.0197e+04,\n",
      "          7.8979e+03,  3.2843e+01,  2.3648e+03,  1.6261e+03],\n",
      "        [ 1.1799e+06,  3.5669e+05,  1.0545e+05, -1.8139e+04,  2.0224e+04,\n",
      "          7.8835e+03, -1.3083e+02,  1.5246e+03,  2.6804e+02],\n",
      "        [ 1.0002e+06,  3.5550e+05,  1.0476e+05, -1.8307e+04,  2.0086e+04,\n",
      "          7.5649e+03,  1.6729e+02,  1.7909e+03,  1.2538e+03],\n",
      "        [ 1.1178e+06,  3.7102e+05,  1.0226e+05, -1.8447e+04,  2.0094e+04,\n",
      "          7.1775e+03, -1.1750e+01,  1.2338e+03,  8.4601e+02],\n",
      "        [ 1.3851e+06,  3.3497e+05,  1.2963e+05, -1.8849e+04,  2.0552e+04,\n",
      "          7.6514e+03,  2.1816e+02,  1.4889e+03,  1.2861e+03],\n",
      "        [ 1.2204e+06,  3.6609e+05,  1.0392e+05, -1.8422e+04,  2.0273e+04,\n",
      "          7.7894e+03, -2.7118e+01,  1.7205e+03,  7.8829e+02],\n",
      "        [ 8.3709e+05,  3.9952e+05,  1.0147e+05, -1.8585e+04,  2.0147e+04,\n",
      "          7.9001e+03, -2.2256e+02,  2.1854e+03,  1.4665e+03],\n",
      "        [-1.6285e+05, -5.6828e+04,  2.3644e+05, -1.8097e+04,  2.0627e+04,\n",
      "          7.8556e+03,  2.0162e+02,  1.9104e+03,  1.2556e+03],\n",
      "        [ 1.1112e+06,  3.7247e+05,  1.0212e+05, -1.7935e+04,  2.0470e+04,\n",
      "          7.5763e+03,  3.2424e+02,  1.2285e+03,  5.3685e+02],\n",
      "        [ 1.1131e+06,  3.6932e+05,  9.9933e+04, -1.8472e+04,  2.0182e+04,\n",
      "          7.4572e+03,  1.6605e+02,  1.3193e+03,  8.8453e+02],\n",
      "        [ 1.0648e+06,  3.6837e+05,  1.0116e+05, -1.8760e+04,  2.0516e+04,\n",
      "          7.6649e+03,  2.5781e+02,  1.2877e+03,  9.1094e+02],\n",
      "        [ 1.0806e+06,  3.6581e+05,  1.0099e+05, -1.8702e+04,  2.0262e+04,\n",
      "          7.8485e+03, -1.1015e+02,  2.1386e+03,  1.6642e+03],\n",
      "        [ 1.2104e+06,  3.5786e+05,  1.0955e+05, -1.8146e+04,  2.0739e+04,\n",
      "          7.5480e+03,  1.0701e+03,  1.4587e+03,  1.8079e+03],\n",
      "        [ 1.3415e+06,  3.7659e+05,  9.9013e+04, -1.8442e+04,  2.0220e+04,\n",
      "          7.6828e+03,  5.1788e+02,  1.4039e+03,  7.3047e+02],\n",
      "        [ 1.1825e+06,  3.9631e+05,  1.0208e+05, -1.8640e+04,  2.0723e+04,\n",
      "          7.8438e+03,  9.0723e+02,  1.3386e+03,  1.2057e+03],\n",
      "        [ 9.9624e+05,  3.7251e+05,  1.0052e+05, -1.8894e+04,  2.0336e+04,\n",
      "          7.7824e+03, -6.4614e+01,  1.8304e+03,  1.4351e+03],\n",
      "        [ 1.1803e+06,  3.9825e+05,  1.1035e+05, -1.8479e+04,  2.0635e+04,\n",
      "          8.2681e+03,  6.3552e+02,  2.1548e+03,  1.3944e+03],\n",
      "        [ 9.5815e+05,  4.0363e+05,  9.9384e+04, -1.7800e+04,  2.0556e+04,\n",
      "          7.3998e+03,  2.7628e+02,  8.8382e+02,  4.6619e+02],\n",
      "        [ 1.9648e+06,  3.8740e+05,  1.0066e+05, -1.8502e+04,  2.0087e+04,\n",
      "          7.7020e+03,  9.0890e+01,  1.7085e+03,  1.1472e+03],\n",
      "        [ 1.3099e+06,  3.6148e+05,  1.0177e+05, -1.8307e+04,  2.0158e+04,\n",
      "          7.6814e+03,  8.4441e+01,  1.9560e+03,  1.3091e+03],\n",
      "        [ 1.3015e+06,  2.9060e+05,  1.3708e+05, -1.8148e+04,  2.0365e+04,\n",
      "          7.5503e+03,  2.6979e+02,  1.2462e+03,  3.1928e+02],\n",
      "        [ 1.1008e+06,  3.2595e+05,  1.2013e+05, -1.8616e+04,  2.0326e+04,\n",
      "          7.4517e+03,  5.8402e+01,  1.3794e+03,  9.1152e+02],\n",
      "        [ 1.0159e+06,  3.9936e+05,  6.5924e+04, -1.8254e+04,  2.0197e+04,\n",
      "          7.9120e+03,  3.1479e+01,  2.0434e+03,  7.9882e+02],\n",
      "        [ 1.4154e+06,  3.9022e+05,  1.0190e+05, -1.8498e+04,  2.0292e+04,\n",
      "          7.7134e+03,  2.3970e+02,  1.6667e+03,  1.1814e+03],\n",
      "        [ 7.6070e+05,  3.9087e+05,  9.9874e+04, -1.8591e+04,  2.0382e+04,\n",
      "          7.7356e+03,  2.6590e+02,  2.3191e+03,  1.9285e+03],\n",
      "        [ 1.1561e+06,  3.7653e+05,  1.0112e+05, -1.8747e+04,  2.0128e+04,\n",
      "          7.4912e+03, -1.7683e+01,  1.4715e+03,  1.0045e+03],\n",
      "        [ 1.3418e+06,  3.8142e+05,  1.0118e+05, -1.8593e+04,  2.0264e+04,\n",
      "          7.8732e+03,  1.0390e+02,  2.1340e+03,  1.5879e+03],\n",
      "        [ 3.7668e+04,  4.3571e+05,  1.0033e+05, -1.8760e+04,  2.0578e+04,\n",
      "          7.5698e+03,  3.6906e+02,  1.1604e+03,  8.1571e+02],\n",
      "        [ 1.2345e+06,  3.7003e+05,  1.3436e+05, -1.8645e+04,  2.0344e+04,\n",
      "          7.6260e+03,  1.8825e+02,  1.4335e+03,  1.0503e+03],\n",
      "        [ 9.1467e+05,  3.9695e+05,  1.0192e+05, -1.8907e+04,  2.0406e+04,\n",
      "          7.8704e+03,  3.1576e+02,  2.4869e+03,  2.0076e+03],\n",
      "        [ 3.5781e+06, -1.4056e+05,  1.0091e+05, -1.8221e+04,  2.0491e+04,\n",
      "          7.5912e+03,  3.6897e+02,  9.9691e+02,  3.6644e+02],\n",
      "        [ 1.1050e+06,  3.2115e+05,  1.1541e+05, -1.8469e+04,  2.0074e+04,\n",
      "          7.2633e+03, -1.1173e+02,  1.3687e+03,  1.0516e+03],\n",
      "        [ 9.6323e+05,  3.8478e+05,  1.0269e+05, -1.8680e+04,  2.0582e+04,\n",
      "          7.5753e+03,  3.5494e+02,  1.1017e+03,  7.1851e+02],\n",
      "        [ 1.4500e+06,  3.5365e+05,  1.0497e+05, -1.8235e+04,  2.0277e+04,\n",
      "          8.0560e+03,  3.8409e+02,  2.1818e+03,  1.2746e+03],\n",
      "        [ 1.5264e+06,  4.4058e+05,  1.0120e+05, -1.8129e+04,  2.0588e+04,\n",
      "          7.6938e+03,  5.7461e+02,  1.1158e+03,  4.4009e+02],\n",
      "        [ 5.5232e+05,  3.6898e+05,  1.8478e+05, -1.8463e+04,  2.0168e+04,\n",
      "          7.8530e+03, -1.9641e+01,  2.3263e+03,  1.5702e+03],\n",
      "        [ 1.1653e+06,  3.7184e+05,  1.0082e+05, -1.8703e+04,  2.0390e+04,\n",
      "          7.6773e+03,  8.6183e+01,  1.5143e+03,  1.2681e+03],\n",
      "        [ 1.1105e+06,  3.6899e+05,  1.0168e+05, -1.8204e+04,  2.0193e+04,\n",
      "          7.4146e+03,  1.6615e+02,  1.5649e+03,  1.1619e+03],\n",
      "        [ 1.2413e+06,  3.8046e+05,  1.0585e+05, -1.8816e+04,  2.0574e+04,\n",
      "          7.5886e+03,  4.8463e+02,  1.4724e+03,  1.5740e+03],\n",
      "        [ 1.1361e+06,  3.8046e+05,  1.0179e+05, -1.8535e+04,  2.0551e+04,\n",
      "          8.2035e+03,  7.3190e+02,  1.9727e+03,  1.1134e+03],\n",
      "        [ 1.4907e+06,  4.1567e+05,  1.0085e+05, -1.8840e+04,  2.0517e+04,\n",
      "          7.6858e+03,  9.7720e+01,  1.3539e+03,  7.1411e+02],\n",
      "        [ 1.0641e+06,  3.7745e+05,  1.0114e+05, -1.8361e+04,  2.0306e+04,\n",
      "          7.4823e+03, -6.5652e+01,  1.5722e+03,  9.8917e+02],\n",
      "        [ 1.0640e+06,  3.6563e+05,  1.1396e+05, -1.8508e+04,  2.0699e+04,\n",
      "          7.8805e+03,  1.5205e+02,  1.9517e+03,  1.3245e+03],\n",
      "        [ 1.7567e+06,  3.5064e+05,  1.0165e+05, -1.8206e+04,  2.0401e+04,\n",
      "          7.5089e+03,  1.0905e+02,  1.5241e+03,  1.1082e+03],\n",
      "        [ 9.3913e+05,  3.8431e+05,  1.0011e+05, -1.8305e+04,  2.0321e+04,\n",
      "          7.6788e+03,  4.0505e+01,  1.1550e+03,  4.4322e+02],\n",
      "        [ 8.6124e+05,  3.6468e+05,  1.0082e+05, -1.8325e+04,  1.9966e+04,\n",
      "          7.5187e+03, -2.1870e+01,  1.6845e+03,  1.1188e+03],\n",
      "        [ 1.1401e+06,  3.7962e+05,  1.0045e+05, -1.8521e+04,  2.0311e+04,\n",
      "          7.5999e+03,  3.2679e+02,  1.4639e+03,  9.7631e+02],\n",
      "        [ 9.4600e+05,  3.8559e+05,  1.0073e+05, -1.9186e+04,  1.9979e+04,\n",
      "          7.9090e+03, -1.3855e+02,  2.3724e+03,  1.4838e+03],\n",
      "        [ 1.1008e+06,  3.7064e+05,  1.0083e+05, -1.8636e+04,  1.9940e+04,\n",
      "          7.2933e+03, -8.5278e+01,  1.6096e+03,  1.2681e+03],\n",
      "        [ 1.0120e+06,  3.6561e+05,  1.0153e+05, -1.8623e+04,  2.0265e+04,\n",
      "          7.6635e+03,  8.9430e+01,  1.6036e+03,  1.0335e+03],\n",
      "        [-6.0332e+05,  4.3981e+05, -3.2796e+05, -1.7979e+04,  2.0594e+04,\n",
      "          7.6163e+03,  4.4875e+02,  1.4439e+03,  1.0004e+03],\n",
      "        [ 1.5452e+06,  5.1242e+04,  1.0481e+05, -1.8783e+04,  2.0217e+04,\n",
      "          7.8482e+03, -1.7219e+02,  2.1340e+03,  1.6827e+03],\n",
      "        [ 1.2374e+06,  3.2981e+05,  1.3246e+05, -1.8327e+04,  2.0423e+04,\n",
      "          8.1246e+03,  4.8203e+02,  2.1698e+03,  1.4259e+03],\n",
      "        [ 1.3667e+06,  4.1263e+05,  1.0130e+05, -1.8860e+04,  2.0488e+04,\n",
      "          7.7381e+03,  2.8504e+02,  1.6522e+03,  1.2306e+03],\n",
      "        [ 1.0195e+06,  3.7320e+05,  1.0251e+05, -1.8361e+04,  2.0375e+04,\n",
      "          7.5748e+03,  8.7472e+01,  1.1306e+03,  6.1332e+02],\n",
      "        [ 1.1342e+06,  2.5872e+05,  1.0856e+05, -1.8278e+04,  2.0230e+04,\n",
      "          7.4738e+03, -5.5812e+01,  1.0738e+03,  5.4920e+02],\n",
      "        [ 1.6244e+06,  5.5994e+05,  9.7153e+04, -1.8331e+04,  2.0728e+04,\n",
      "          7.5507e+03,  7.7773e+02,  1.4148e+03,  1.5560e+03],\n",
      "        [ 6.8087e+05,  3.7564e+05,  1.0082e+05, -1.8272e+04,  2.0534e+04,\n",
      "          7.4767e+03,  2.9323e+02,  9.7235e+02,  5.9375e+02],\n",
      "        [ 1.3071e+06,  3.5654e+05,  1.0179e+05, -1.7919e+04,  2.0434e+04,\n",
      "          7.6236e+03,  2.0768e+02,  1.2907e+03,  3.1576e+02],\n",
      "        [ 1.0824e+06,  3.6888e+05,  1.0352e+05, -1.8374e+04,  2.0133e+04,\n",
      "          7.3566e+03,  1.4858e+02,  1.5696e+03,  9.2693e+02],\n",
      "        [ 1.1674e+06,  3.6244e+05,  1.0085e+05, -1.8341e+04,  2.0292e+04,\n",
      "          7.8313e+03, -2.5133e+01,  2.0366e+03,  1.3178e+03],\n",
      "        [ 1.1133e+06,  3.6395e+05,  9.4968e+04, -1.8348e+04,  2.0712e+04,\n",
      "          7.5241e+03,  9.0064e+02,  1.2363e+03,  1.0238e+03],\n",
      "        [ 1.9828e+06,  5.0533e+05,  1.0782e+05, -1.7903e+04,  2.0730e+04,\n",
      "          7.4824e+03,  6.5850e+02,  9.4444e+02,  5.0334e+02],\n",
      "        [ 1.1167e+06,  3.4349e+05,  9.8250e+04, -1.8152e+04,  2.0359e+04,\n",
      "          7.8656e+03,  4.9835e+02,  1.7647e+03,  1.0526e+03],\n",
      "        [ 1.3574e+06,  3.7015e+05,  1.0246e+05, -1.8716e+04,  2.0072e+04,\n",
      "          8.0037e+03, -3.0442e+02,  2.1897e+03,  1.1449e+03],\n",
      "        [ 1.3872e+06,  3.6485e+05,  1.0061e+05, -1.8206e+04,  2.0525e+04,\n",
      "          8.1396e+03,  3.9627e+02,  2.2717e+03,  1.6059e+03],\n",
      "        [ 1.1437e+06,  3.7677e+05,  1.0350e+05, -1.8344e+04,  2.0169e+04,\n",
      "          7.8308e+03,  5.0247e+01,  1.8880e+03,  9.4170e+02],\n",
      "        [ 1.1210e+06,  3.6248e+05,  1.0174e+05, -1.8432e+04,  2.0329e+04,\n",
      "          7.1522e+03, -1.4591e+02,  1.0533e+03,  8.7190e+02],\n",
      "        [ 1.0755e+06,  3.6576e+05,  1.0236e+05, -1.7916e+04,  2.0600e+04,\n",
      "          7.6189e+03,  5.9222e+02,  1.3644e+03,  8.7473e+02],\n",
      "        [ 1.0342e+06,  3.4883e+05,  1.0360e+05, -1.7892e+04,  2.0529e+04,\n",
      "          7.5258e+03,  4.2705e+02,  1.2934e+03,  7.8069e+02],\n",
      "        [ 1.3231e+06,  3.8340e+05,  1.0125e+05, -1.8700e+04,  2.0260e+04,\n",
      "          7.7693e+03,  4.2460e+01,  1.7409e+03,  1.3023e+03]])\n"
     ]
    }
   ],
   "source": [
    "print(angles_sample.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logdet = model.sample_and_log_prob(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss = (loss + logdet[:, None]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0239, -0.3383,  0.3175,  ..., -0.1333, -0.3284, -0.4040],\n",
       "        [-0.1827,  1.1365, -0.5813,  ..., -0.3947,  0.3445,  0.7744],\n",
       "        [-0.0460,  0.5030, -0.5148,  ..., -0.1440,  0.2224,  0.9553],\n",
       "        ...,\n",
       "        [ 0.9095, -0.1586,  0.2059,  ...,  0.0287, -0.6542, -0.1489],\n",
       "        [-0.2702, -0.0838,  0.3339,  ..., -0.3490,  0.1917, -0.4530],\n",
       "        [-0.1773,  0.2773, -0.5189,  ..., -0.1973, -0.0033,  0.5414]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model._transform._transforms[0]._transforms[1].conditioner.linear1.weight.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 17])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = torch.rand(size=(4, 17))\n",
    "k = torch.rand(size=(4, 17))\n",
    "l = torch.rand(size=(4, 17))\n",
    "ls = [j, k, l]\n",
    "torch.stack(ls).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8167, 0.5797, 3.3655, 0.3703],\n",
       "         [0.7785, 2.3855, 0.4710, 2.0032],\n",
       "         [0.9357, 2.4022, 0.5809, 1.4372],\n",
       "         [0.9357, 2.4022, 0.4772, 0.6444],\n",
       "         [0.8134, 0.5167, 0.5041, 1.9168]]),\n",
       " tensor([[-2.0675, -1.5534,     nan, -0.5470],\n",
       "         [-2.0675,     nan, -1.2066,     nan],\n",
       "         [    nan,     nan, -0.1418,     nan],\n",
       "         [    nan,     nan, -1.2066, -1.1884],\n",
       "         [-2.0675, -1.5534, -0.1418,     nan]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "i=torch.rand(size=(5,4))\n",
    "j=torch.rand(size=(4, 17))\n",
    "k=torch.rand(size=(4, 17))\n",
    "l=torch.rand(size=(4, 17))\n",
    "from models.spline import _rational_quadratic_spline_fwd\n",
    "_rational_quadratic_spline_fwd(i,j,k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "def _rqs_fwd_single(x: Tensor,\n",
    "                                   x_pos: Tensor,\n",
    "                                   y_pos: Tensor,\n",
    "                                   knot_slopes: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "  \"\"\"Applies a rational-quadratic spline to a scalar.\n",
    "  Args:\n",
    "    x: a scalar (0-dimensional array). The scalar `x` can be any real number; it\n",
    "      will be transformed by the spline if it's in the closed interval\n",
    "      `[x_pos[0], x_pos[-1]]`, and it will be transformed linearly if it's\n",
    "      outside that interval.\n",
    "    x_pos: array of shape [num_bins + 1], the bin boundaries on the x axis.\n",
    "    y_pos: array of shape [num_bins + 1], the bin boundaries on the y axis.\n",
    "    knot_slopes: array of shape [num_bins + 1], the slopes at the knot points.\n",
    "  Returns:\n",
    "    A tuple of two scalars: the output of the transformation and the log of the\n",
    "    absolute first derivative at `x`.\n",
    "  \"\"\"\n",
    "  # Search to find the right bin. NOTE: The bins are sorted, so we could use\n",
    "  # binary search, but this is more GPU/TPU friendly.\n",
    "  # The following implementation avoids indexing for faster TPU computation.\n",
    "  below_range = x <= x_pos[0]\n",
    "  above_range = x >= x_pos[-1]\n",
    "  correct_bin = torch.logical_and(x >= x_pos[:-1], x < x_pos[1:])\n",
    "  any_bin_in_range = torch.any(correct_bin)\n",
    "  first_bin = torch.concat([torch.tensor([1], dtype=bool),\n",
    "                               torch.zeros(len(correct_bin)-1, dtype=bool)])\n",
    "  # If y does not fall into any bin, we use the first spline in the following\n",
    "  # computations to avoid numerical issues.\n",
    "  correct_bin = torch.where(any_bin_in_range, correct_bin, first_bin)\n",
    "  # Dot product of each parameter with the correct bin mask.\n",
    "  params = torch.stack([x_pos, y_pos, knot_slopes], axis=1)\n",
    "  params_bin_left = torch.sum(correct_bin[:, None] * params[:-1], axis=0)\n",
    "  params_bin_right = torch.sum(correct_bin[:, None] * params[1:], axis=0)\n",
    "\n",
    "  x_pos_bin = (params_bin_left[0], params_bin_right[0])\n",
    "  y_pos_bin = (params_bin_left[1], params_bin_right[1])\n",
    "  knot_slopes_bin = (params_bin_left[2], params_bin_right[2])\n",
    "\n",
    "  bin_width = x_pos_bin[1] - x_pos_bin[0]\n",
    "  bin_height = y_pos_bin[1] - y_pos_bin[0]\n",
    "  bin_slope = bin_height / bin_width\n",
    "\n",
    "  z = (x - x_pos_bin[0]) / bin_width\n",
    "  # `z` should be in range [0, 1] to avoid NaNs later. This can happen because\n",
    "  # of small floating point issues or when x is outside of the range of bins.\n",
    "  # To avoid all problems, we restrict z in [0, 1].\n",
    "  z = torch.clip(z, 0., 1.)\n",
    "  sq_z = z * z\n",
    "  z1mz = z - sq_z  # z(1-z)\n",
    "  sq_1mz = (1. - z) ** 2\n",
    "  slopes_term = knot_slopes_bin[1] + knot_slopes_bin[0] - 2. * bin_slope\n",
    "  numerator = bin_height * (bin_slope * sq_z + knot_slopes_bin[0] * z1mz)\n",
    "  denominator = bin_slope + slopes_term * z1mz\n",
    "  y = y_pos_bin[0] + numerator / denominator\n",
    "\n",
    "  # Compute log det Jacobian.\n",
    "  # The logdet is a sum of 3 logs. It is easy to see that the inputs of the\n",
    "  # first two logs are guaranteed to be positive because we ensured that z is in\n",
    "  # [0, 1]. This is also true of the log(denominator) because:\n",
    "  # denominator\n",
    "  # == bin_slope + (knot_slopes_bin[1] + knot_slopes_bin[0] - 2 * bin_slope) *\n",
    "  # z*(1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * z * (1-z)\n",
    "  # >= bin_slope - 2 * bin_slope * (1/4)\n",
    "  # == bin_slope / 2\n",
    "  logdet = 2. * torch.log(bin_slope) + torch.log(\n",
    "      knot_slopes_bin[1] * sq_z + 2. * bin_slope * z1mz +\n",
    "      knot_slopes_bin[0] * sq_1mz) - 2. * torch.log(denominator)\n",
    "\n",
    "  # If x is outside the spline range, we default to a linear transformation.\n",
    "  y = torch.where(below_range, (x - x_pos[0]) * knot_slopes[0] + y_pos[0], y)\n",
    "  y = torch.where(above_range, (x - x_pos[-1]) * knot_slopes[-1] + y_pos[-1], y)\n",
    "  logdet = torch.where(below_range, torch.log(knot_slopes[0]), logdet)\n",
    "  logdet = torch.where(above_range, torch.log(knot_slopes[-1]), logdet)\n",
    "  return y, logdet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 1.2628, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModule(torch.nn.Module):\n",
    "    \n",
    "    def _func(self, input):\n",
    "        return input * input\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self._func(input[2, 2])\n",
    "    \n",
    "testModule = TestModule()\n",
    "i=torch.rand(size=(10, 10), requires_grad=True)\n",
    "out=testModule(i).sum()\n",
    "out.backward()\n",
    "i.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "729135a7fed3b567d634efcd54e452b1f1e9c908d616bc775570d26a0a8b03e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
